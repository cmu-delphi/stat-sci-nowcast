{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef9c5c3",
   "metadata": {},
   "source": [
    "# Generate KM-adjusted delay distributions\n",
    "\n",
    "Data downloaded from public CDC linelist on September 9, 2021.\n",
    "\n",
    "https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data/vbim-akqf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71194746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "\n",
    "# third party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from pandas import read_csv, date_range, Series\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# first party\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d7937",
   "metadata": {},
   "source": [
    "## Read in linelist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveil_df = read_csv(\"../data/COVID-19_Case_Surveillance_Public_Use_Data_20210909.csv\",\n",
    "                      usecols=[\"cdc_report_dt\", \"onset_dt\"],\n",
    "                      parse_dates=[\"cdc_report_dt\", \"onset_dt\"])\n",
    "surveil_df.onset_dt = surveil_df.onset_dt.dt.date\n",
    "surveil_df.cdc_report_dt = surveil_df.cdc_report_dt.dt.date\n",
    "\n",
    "# Remove missing onset rows, and data prior to our assumed first reliable day of data.\n",
    "linelist = surveil_df[~surveil_df.onset_dt.isna()]\n",
    "linelist = linelist[linelist.cdc_report_dt.ge(Config.first_data_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24a93b",
   "metadata": {},
   "source": [
    "## Calculate reporting delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0218e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linelist['report_delay'] = (linelist.cdc_report_dt - linelist.onset_dt).dt.days\n",
    "linelist = linelist[linelist.report_delay.gt(0) & linelist.report_delay.le(Config.max_delay_days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b07689",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = '../data/km_delay_distributions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ddb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_pmf(delay_df, \n",
    "                  max_delay=Config.max_delay_days,\n",
    "                  distribution_support=Config.distribution_support):\n",
    "    delays = delay_df[delay_df.report_delay.le(max_delay)]\n",
    "    emp_dist = delays.groupby('report_delay').onset_dt.count()\n",
    "    emp_dist /= emp_dist.sum()\n",
    "    emp_dist = emp_dist.reindex(distribution_support, fill_value=0)\n",
    "    return emp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_training_pmfs(linelist, as_of, Config=Config):\n",
    "    d = Config.support_size\n",
    "    window_size = 2*d\n",
    "    support = Config.distribution_support\n",
    "        \n",
    "    last_truncated = as_of - timedelta(Config.max_delay_days)\n",
    "    truncated_dates = [d.date() for d in date_range(last_truncated, as_of)]\n",
    "    fair_df = linelist[linelist.cdc_report_dt.lt(as_of)]\n",
    "    \n",
    "    pmfs = {}\n",
    "    for working_onset_date in tqdm(truncated_dates):\n",
    "        t = as_of\n",
    "        i = (t - working_onset_date).days\n",
    "        running_kernel = Series([0]).reindex(support, fill_value=0)\n",
    "        \n",
    "        min_date = t - timedelta(i) - timedelta(window_size) + timedelta(1)\n",
    "        max_date = t - timedelta(d)\n",
    "        \n",
    "        trimmed_df = fair_df[fair_df.onset_dt.ge(min_date)]\n",
    "        D_tilde = trimmed_df[trimmed_df.onset_dt.le(max_date)]\n",
    "        update = empirical_pmf(D_tilde, d)\n",
    "        if i == d:\n",
    "            running_kernel = update\n",
    "        else:\n",
    "            running_kernel.loc[d] = update.loc[d]\n",
    "            survival = update.loc[d]\n",
    "            for j in range(d-1, i-1, -1):\n",
    "                max_date = t - timedelta(j)\n",
    "                D_tilde = trimmed_df[trimmed_df.onset_dt.le(max_date)]\n",
    "                update = empirical_pmf(D_tilde, j) * (1 - survival)\n",
    "                if j > i:\n",
    "                    running_kernel.loc[j] = update.loc[j]\n",
    "                    survival += update.loc[j]\n",
    "                else:\n",
    "                    running_kernel.loc[:j] = update.loc[:j]\n",
    "\n",
    "        assert np.isclose(running_kernel.sum(), 1), working_onset_date\n",
    "        \n",
    "        # Fit gamma distribution\n",
    "        mu = (running_kernel*support).sum()\n",
    "        var = (running_kernel*(support**2)).sum() - mu**2\n",
    "        gam = stats.gamma(mu**2 / var, loc=0, scale=(var / mu))\n",
    "        delay_dist = np.array([gam.cdf(i+1) - gam.cdf(i) for i in support])\n",
    "        delay_dist /= delay_dist.sum()\n",
    "        pmfs[working_onset_date] = np.r_[0, delay_dist] # Add pr 0 at lag=0\n",
    "\n",
    "    return pmfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for as_of in Config.as_of_range:\n",
    "    pmfs = construct_training_pmfs(linelist, as_of)\n",
    "    pickle.dump(pmfs, open(f'{storage_dir}/delay_distribution_as_of_{as_of}.p', 'wb'),\n",
    "               protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f046ae6",
   "metadata": {},
   "source": [
    "### Add extra past\n",
    "\n",
    "- For each working date `s` older than `d` days, we have fully observed all the possible reporting dates (no need to truncate by report date). Hence, we can simply take the rows where the symptom onset date falls in `[s - 2*d + 1, s]`. We first construct all of these pmfs, and then fill in the extra past for the training kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_observed_pmfs = pickle.load(open('../data/naive_delay_distributions/uncensored_delay_distribution.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27507a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in delay distribution pickles\n",
    "first_data_date = Config.first_data_date\n",
    "d = Config.max_delay_days\n",
    "for run_date in tqdm(Config.as_of_range):\n",
    "    try:\n",
    "        pmfs = pickle.load(open(f'{storage_dir}/delay_distribution_as_of_{run_date}.p', 'rb'))\n",
    "    except Exception as e:\n",
    "        print(run_date, \"missing\")\n",
    "        continue\n",
    "\n",
    "    first_uncensored_date = run_date - timedelta(d) - timedelta(1)\n",
    "    if first_uncensored_date <= first_data_date:\n",
    "        print(run_date)\n",
    "        continue \n",
    "    \n",
    "    uncensored_range = [d.date() for d in date_range(first_data_date, first_uncensored_date)]\n",
    "    existing_working_dates = sorted(pmfs.keys())\n",
    "    assert run_date == existing_working_dates[-1]\n",
    "    \n",
    "    for working_onset_date in uncensored_range:\n",
    "        pmfs[working_onset_date] = fully_observed_pmfs[working_onset_date]\n",
    "        \n",
    "    assert len(pmfs) == (run_date - first_data_date).days + 1\n",
    "    pickle.dump(pmfs, \n",
    "                open(f'{storage_dir}/delay_distribution_as_of_{run_date}.p', 'wb'), \n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example of error\n",
    "naive = pickle.load(open(f'../data/naive_delay_distributions/delay_distribution_as_of_{as_of}.p', 'rb'))\n",
    "truth = pickle.load(open(f'../data/naive_delay_distributions/uncensored_delay_distribution.p', 'rb'))\n",
    "\n",
    "err_adjusted = []\n",
    "err_naive = []\n",
    "for i in range(50):\n",
    "    a = as_of - timedelta(i)\n",
    "    err_adjusted.append(np.sum(np.abs(pmfs[a] - truth[a])))\n",
    "    err_naive.append(np.sum(np.abs(naive[a] - truth[a])))\n",
    "plt.plot(err_adjusted, color='tab:blue', label='km')\n",
    "plt.plot(err_naive, color='tab:orange', label='naive')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}