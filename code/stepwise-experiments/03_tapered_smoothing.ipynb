{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24041a02",
   "metadata": {},
   "source": [
    "# Tapered smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3744217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# first party\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73353125",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "\n",
    "The results are the output of `03_tapered_smoothing.py`, and should be stored in `../results/tapered_smoothing/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(a_dict):\n",
    "    out = []\n",
    "    for key, val in a_dict.items():\n",
    "        if val.data is None:\n",
    "            continue\n",
    "        out.append(pd.DataFrame({'x': val.values, 'loc': val.geo_value, 'dates': val.dates}))\n",
    "    out = pd.concat(out)\n",
    "    out.set_index(['loc', 'dates'], inplace=True)\n",
    "    return out\n",
    "\n",
    "truth = to_dataframe(pickle.load(open('../data/tf_ground_truths.p', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = './results/tapered_smoothing/'\n",
    "as_of_date_range = Config.every_10_as_of_range\n",
    "\n",
    "output = defaultdict(list)\n",
    "for as_of in as_of_date_range:\n",
    "    print(as_of)\n",
    "    result = pickle.load(open(f'{storage_dir}/as_of_{as_of}.p', 'rb'))\n",
    "    if len(result.keys()) != 2:\n",
    "        print('Not all options ran on', as_of, 'skipping')\n",
    "        continue \n",
    "    for method, method_data in result.items():\n",
    "        predictions = to_dataframe(method_data)\n",
    "        errors = (truth - predictions).dropna().reset_index()\n",
    "        errors['as_of'] = as_of\n",
    "        output[method].append(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d35b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = []\n",
    "for method, method_data in output.items():\n",
    "    all_errors = pd.concat(method_data)\n",
    "    all_errors['method'] = method\n",
    "    all_errors['abs_err'] = np.abs(all_errors.x)\n",
    "    all_errors['lag'] = (pd.to_datetime(all_errors.as_of) - all_errors.dates).dt.days \n",
    "    analysis.append(all_errors)\n",
    "    \n",
    "analysis = pd.concat(analysis, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.replace(\n",
    "    {'tf_tapered': 'Trend filtering (tapered)',\n",
    "     'ntf_tapered': 'Natural trend filtering (tapered)'},\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from natural_constraints_02\n",
    "untapered_analysis = pickle.load(open('natural_constraints_02_analysis.p', 'rb'))\n",
    "analysis = pd.concat([analysis, untapered_analysis], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.groupby(['lag', 'dates', 'method']).count().x.std() # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7091af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_order = ['Trend filtering', 'Natural trend filtering',\n",
    "             'Trend filtering (tapered)', 'Natural trend filtering (tapered)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bdc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    " data=analysis[analysis.lag.le(Config.max_delay_days)],\n",
    " x='lag',\n",
    " y='abs_err',\n",
    " hue='method',\n",
    " style='method',\n",
    " hue_order=hue_order,\n",
    " markers=True,\n",
    " err_kws={'alpha': 0.1}\n",
    ")\n",
    "plt.title('Boundary regularization in deconvolution')\n",
    "plt.ylabel('Mean absolute error')\n",
    "plt.xlabel('Days back from nowcast time')\n",
    "plt.legend(title=None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.lineplot(\n",
    " data=analysis[analysis.lag.le(10)],\n",
    " x='lag',\n",
    " y='abs_err',\n",
    " hue='method',\n",
    " hue_order=hue_order,\n",
    " style='method',\n",
    " markers=True,\n",
    " err_kws={'alpha': 0.1}\n",
    ")\n",
    "plt.title('Boundary regularization in deconvolution')\n",
    "plt.ylabel('Mean absolute error')\n",
    "plt.xlabel('Days back from nowcast time')\n",
    "plt.legend(title=None)\n",
    "plt.xticks(range(2, 11, 2))\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/tapered_smoothing_03_small_square.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}