{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b74d7e",
   "metadata": {},
   "source": [
    "# Evaluate fusion methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# third party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# first party\n",
    "from config import Config\n",
    "from data_containers import LocationSeries, SensorConfig, Sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Directory:\n",
    "    ROOT = '../data/'\n",
    "    \n",
    "    def __init__(self, gt_indicator = Config.ground_truth_indicator):\n",
    "        self.gt = gt_indicator\n",
    "        self.infections_root_dir = './results/ntf_tapered/'\n",
    "        self.indicator_root_dir = os.path.join(Directory.ROOT, 'indicators')\n",
    "        self.sensor_root_dir = os.path.join(Directory.ROOT, 'sensors')\n",
    "        self.jhu_path = os.path.join(\n",
    "            Directory.ROOT, f'jhu-csse_confirmed_incidence_prop/{self.gt.source}_{self.gt.signal}')\n",
    "       \n",
    "    def deconv_gt_file(self, as_of):\n",
    "        return os.path.join(self.infections_root_dir, f'as_of_{as_of}.p')\n",
    "    \n",
    "    def indicator_file(self, indicator, as_of):\n",
    "        return os.path.join(\n",
    "            self.indicator_root_dir,\n",
    "            f'{indicator.source}-{indicator.signal}_{as_of}.p')\n",
    "    \n",
    "    def sensor_file(self, config, as_of):\n",
    "        return os.path.join(\n",
    "            self.sensor_root_dir,\n",
    "            f'{config.source}_{config.signal}_{as_of}.p')\n",
    "    \n",
    "    def maybe_load_file(self, file_name, verbose=False):\n",
    "        if not os.path.isfile(file_name):\n",
    "            if verbose:\n",
    "                print(file_name, 'does not exist')\n",
    "            return False\n",
    "        \n",
    "        return pickle.load(open(file_name, 'rb'))\n",
    "    \n",
    "    def maybe_write_file(self, data, file_name, overwrite=False, verbose=False):\n",
    "        if os.path.isfile(file_name) and not overwrite:\n",
    "            if verbose:\n",
    "                print(file_name, 'exists')\n",
    "            return False\n",
    "        \n",
    "        dir_name = os.path.dirname(file_name)\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)   \n",
    "        \n",
    "        pickle.dump(data, open(file_name, 'wb'))\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def exists(file_name, overwrite=False):\n",
    "        if os.path.isfile(file_name) and not overwrite:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def conform(location_series):\n",
    "    if location_series is None:\n",
    "        return None\n",
    "    \n",
    "    if location_series.data is None or np.isnan(location_series.values).all():\n",
    "        return None\n",
    "    \n",
    "    if isinstance(location_series.dates[0], datetime):\n",
    "        location_series.data = dict(zip([d.date() for d in location_series.dates],\n",
    "                                        location_series.values))\n",
    "    return location_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up all the method configurations.\n",
    "# The 'fast_' versions use a subset of lower-latency sensors\n",
    "infections_config = SensorConfig('jhu-csse', 'confirmed_incidence_prop','deconv_infections', 2)\n",
    "ar3_config = SensorConfig('ar3', 'ntf_tapered_infections', 'ar3', lag=1)\n",
    "simple_avg_config = SensorConfig('all', 'simple_average', 'average', 4)\n",
    "fast_simple_avg_config = SensorConfig('fast_all', 'simple_average', 'average', 1)\n",
    "simple_avg_no_google_aa_config = SensorConfig('all_no_google_aa', 'simple_average', 'average', 4)\n",
    "fast_simple_avg_no_google_aa_config= SensorConfig('fast_all_no_google_aa', 'simple_average', 'average', 1)\n",
    "\n",
    "simple_reg_config = SensorConfig('all', 'simple_reg', 'regression', 4)\n",
    "fast_simple_reg_config = SensorConfig('fast_all', 'simple_reg', 'regression', 1)\n",
    "\n",
    "ridge_config = SensorConfig('all', 'ridge', 'ridge', 4)\n",
    "fast_ridge_config = SensorConfig('fast_all', 'ridge', 'ridge', 1)\n",
    "\n",
    "lasso_config = SensorConfig('all', 'lasso', 'lasso', 4)\n",
    "fast_lasso_config = SensorConfig('fast_all', 'lasso', 'lasso', 1)\n",
    "\n",
    "kf_sf_config = SensorConfig('all', 'kf_sf', 'kf_sf', 4)\n",
    "fast_kf_sf_config = SensorConfig('fast_all', 'kf_sf', 'kf_sf', 1)\n",
    "\n",
    "max_eval_lag = 10\n",
    "directory = Directory(infections_config)\n",
    "states = sorted(Config.states - set(['dc']))\n",
    "evaluation_geos = sorted(set(states) | (Config.top_counties - set(['11001'])))\n",
    "get_geo_type = lambda x: 'county' if x.isnumeric() else 'state'\n",
    "state_map = {}\n",
    "for state in states:\n",
    "    fips_code = Config.state_fips[state]\n",
    "    state_map[state] = [geo for geo in evaluation_geos if geo == state or geo[:2] == fips_code] \n",
    "\n",
    "# testing dates are those not used in previous experiments\n",
    "as_of_range = Config.as_of_range\n",
    "evaluation_as_of_range = [d for d in as_of_range if d not in set(Config.every_10_as_of_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d1597",
   "metadata": {},
   "source": [
    "## Load sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sensors(as_of_range, sensor_configs, directory):\n",
    "    sensors = Sensors()\n",
    "    for as_of in tqdm(as_of_range):\n",
    "        for sensor, config in sensor_configs.items():\n",
    "            sensor_file = directory.sensor_file(config, as_of)\n",
    "            sensor_data = directory.maybe_load_file(sensor_file)\n",
    "            if not sensor_data:\n",
    "                continue\n",
    "            for k in sensor_data.keys():\n",
    "                vals = conform(sensor_data[k])\n",
    "                if vals is None:\n",
    "                    continue\n",
    "                sensors.add_data(as_of, sensor, sensor_data[k].geo_value, vals)\n",
    "    return sensors\n",
    "\n",
    "indicator_sensors = {\n",
    "    'fb_cliic': Config.fb_cliic,\n",
    "    'dv_cli': Config.dv_cli,\n",
    "    'google_aa': Config.google_aa,\n",
    "    'chng_cli': Config.chng_cli,\n",
    "    'chng_covid': Config.chng_covid,\n",
    "    'ar3': ar3_config,\n",
    "}\n",
    "\n",
    "fusion_sensors = {\n",
    "    'simple_avg': simple_avg_config,\n",
    "    'fast_simple_avg': fast_simple_avg_config,\n",
    "    'simple_avg_no_google_aa': simple_avg_no_google_aa_config,\n",
    "    'fast_simple_avg_no_google_aa': fast_simple_avg_no_google_aa_config,\n",
    "    'simple_reg': simple_reg_config,\n",
    "    'fast_simple_reg': fast_simple_reg_config,\n",
    "    'ridge': ridge_config,   \n",
    "    'fast_ridge': fast_ridge_config,\n",
    "    'lasso': lasso_config,\n",
    "    'fast_lasso': fast_lasso_config,\n",
    "    'kf_sf': kf_sf_config,\n",
    "    'fast_kf_sf': fast_kf_sf_config,\n",
    "}\n",
    "\n",
    "indicator_sensor_data = load_sensors(as_of_range, indicator_sensors, directory)\n",
    "fusion_sensor_data = load_sensors(as_of_range, fusion_sensors, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace kf_sf predictions in states where there are no subcounties\n",
    "for state in states:\n",
    "    if len(state_map[state]) == 1:\n",
    "        present_dates = fusion_sensor_data.data.keys()\n",
    "        for as_of in present_dates:\n",
    "            data = fusion_sensor_data.data[as_of]\n",
    "            if 'kf_sf' in data:\n",
    "                fusion_sensor_data.data[as_of]['kf_sf'][state] = data['ridge'][state]\n",
    "            if 'fast_kf_sf' in data:\n",
    "                fusion_sensor_data.data[as_of]['fast_kf_sf'][state] = data['fast_ridge'][state]\n",
    "        print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in natural trend filtering estimates\n",
    "for as_of in tqdm(as_of_range):\n",
    "    infections_file = directory.deconv_gt_file(as_of)\n",
    "    data = directory.maybe_load_file(infections_file)\n",
    "    assert data is not None, as_of\n",
    "\n",
    "    for k in data.keys():\n",
    "        vals = conform(data[k])\n",
    "        if vals is None:\n",
    "            continue\n",
    "        indicator_sensor_data.add_data(as_of, 'ntf_tapered', k, vals)\n",
    "        fusion_sensor_data.add_data(as_of, 'ntf_tapered', k, vals)\n",
    "        \n",
    "indicator_sensors['ntf_tapered'] = infections_config\n",
    "fusion_sensors['ntf_tapered'] = infections_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067dfd7",
   "metadata": {},
   "source": [
    "## Compute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fecccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pickle.load(open('../data/tf_ground_truths.p', 'rb'))\n",
    "df = lambda ls: pd.DataFrame.from_dict(ls.data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21caf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "for as_of in tqdm(as_of_range):\n",
    "    output = []\n",
    "    for geo in evaluation_geos:\n",
    "        x = df(truth[geo])\n",
    "        for sensor, config in indicator_sensors.items():\n",
    "            x_hat = indicator_sensor_data.get_data(as_of, sensor, geo)\n",
    "            if x_hat is None:\n",
    "                continue\n",
    "            x_hat = df(x_hat)\n",
    "            err = np.abs((x - x_hat).dropna()).reset_index()\n",
    "            err.columns = ['dates', 'abs_err']\n",
    "            err['as_of'] = as_of\n",
    "            err['geo'] = geo\n",
    "            err['sensor'] = sensor\n",
    "            err['lag'] = (pd.to_datetime(as_of) - err.dates).dt.days \n",
    "            err = err[err.lag.le(max_eval_lag)]\n",
    "            output.append(err)\n",
    "    output = pd.concat(output, ignore_index=True)\n",
    "    pickle.dump(output, open(f'./results/errors/indicator_{as_of}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for as_of in tqdm(as_of_range):\n",
    "    out_file = f'./results/errors/fusion_{as_of}.p'\n",
    "    output = []\n",
    "    for geo in evaluation_geos:\n",
    "        x = df(truth[geo])\n",
    "        for sensor, config in fusion_sensors.items():\n",
    "            x_hat = fusion_sensor_data.get_data(as_of, sensor, geo)\n",
    "            if x_hat is None:\n",
    "                continue\n",
    "            x_hat = df(x_hat)\n",
    "            err = np.abs((x - x_hat).dropna()).reset_index()\n",
    "            err.columns = ['dates', 'abs_err']\n",
    "            err['as_of'] = as_of\n",
    "            err['geo'] = geo\n",
    "            err['sensor'] = sensor\n",
    "            err['lag'] = (pd.to_datetime(as_of) - err.dates).dt.days \n",
    "            err = err[err.lag.le(max_eval_lag)]\n",
    "            output.append(err)\n",
    "    output = pd.concat(output, ignore_index=True)\n",
    "    pickle.dump(output, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d0b0d",
   "metadata": {},
   "source": [
    "## Plotting maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acddfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_map = {\n",
    "    'ntf_tapered': 'NTF (tapered)',\n",
    "    'simple_avg': 'Simple average (+claims)',\n",
    "    'fast_simple_avg': 'Simple average',\n",
    "    'simple_avg_no_google_aa': 'Simple average (+claims) (-google-aa)',\n",
    "    'fast_simple_avg_no_google_aa': 'Simple average (-google-aa)',\n",
    "    'simple_reg': 'Simple regression (+claims)',\n",
    "    'fast_simple_reg': 'Simple regression',\n",
    "    'ridge': 'Ridge (+claims)',\n",
    "    'fast_ridge': 'Ridge',\n",
    "    'lasso': 'Lasso (+claims)',\n",
    "    'fast_lasso': 'Lasso',\n",
    "    'kf_sf': 'KF-SF (+claims)',\n",
    "    'fast_kf_sf': 'KF-SF',\n",
    "    'ar3': 'AR(3)', \n",
    "    'dv_cli': 'DV-CLI',\n",
    "    'chng_cli': 'CHNG-CLI',\n",
    "    'chng_covid': 'CHNG-COVID',\n",
    "    'fb_cliic': 'CTIS-CLIIC',\n",
    "    'google_aa': 'Google-AA',\n",
    "}\n",
    "\n",
    "color_map = {\n",
    "    'NTF (tapered)': '#949494',\n",
    "    'Simple average': '#0173B2',\n",
    "    'Simple regression': '#DE8F05',\n",
    "    'Ridge': '#1f7a34',\n",
    "    'Lasso': '#56B4E9',\n",
    "    'KF-SF': '#CC78BC',\n",
    "    'AR(3)': '#CA9161',\n",
    "    'DV-CLI': '#029E73',\n",
    "    'CHNG-CLI': 'brown',\n",
    "    'CHNG-COVID': 'tab:purple',\n",
    "    'CTIS-CLIIC': '#FBAFE4',\n",
    "    'Google-AA': '#ECE133',\n",
    "}\n",
    "\n",
    "marker_map = {\n",
    "    'NTF (tapered)': 'd',\n",
    "    'Simple average': 'o',\n",
    "    'Simple regression': 'o',\n",
    "    'Ridge': 'o',\n",
    "    'Lasso': 'o',\n",
    "    'KF-SF': 'o',\n",
    "    'AR(3)': 'd',\n",
    "    'DV-CLI': 'd',\n",
    "    'CHNG-CLI': 'd',\n",
    "    'CHNG-COVID': 'd',\n",
    "    'CTIS-CLIIC': 'd',\n",
    "    'Google-AA': 'd',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f44c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_latency = {\n",
    "    1: ['CTIS-CLIIC', 'Google-AA', 'AR(3)',\n",
    "        'Simple average', 'Simple regression',\n",
    "        'Ridge', 'Lasso', 'KF-SF']\n",
    "}\n",
    "sensor_latency[2] = sensor_latency[1] + ['NTF (tapered)']\n",
    "sensor_latency[3] = sensor_latency[2]\n",
    "sensor_latency[4] = sensor_latency[2] + ['CHNG-CLI', 'CHNG-COVID', 'DV-CLI']\n",
    "for lag in range(5, max_eval_lag + 1):\n",
    "    sensor_latency[lag] = sensor_latency[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_err_df = []\n",
    "fusion_err_df = []\n",
    "for as_of in tqdm(evaluation_as_of_range):\n",
    "    sensor_err = pickle.load(open(f'./results/errors/indicator_{as_of}.p', 'rb'))\n",
    "    fusion_err = pickle.load(open(f'./results/errors/fusion_{as_of}.p', 'rb'))\n",
    "    sensor_err_df.append(sensor_err)\n",
    "    fusion_err_df.append(fusion_err)\n",
    "    \n",
    "sensor_err_df = pd.concat(sensor_err_df, ignore_index=True)\n",
    "fusion_err_df = pd.concat(fusion_err_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_err_df = sensor_err_df.replace(legend_map)\n",
    "fusion_err_df = fusion_err_df.replace(legend_map)\n",
    "all_err_df = pd.concat([sensor_err_df, fusion_err_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_err_df = all_err_df[all_err_df.lag.le(max_eval_lag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_index = pd.MultiIndex.from_product([evaluation_geos, evaluation_as_of_range], names=['geo', 'as_of'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6094d99",
   "metadata": {},
   "source": [
    "## Sensor availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensors = [\n",
    "    'NTF (tapered)',  \n",
    "    'AR(3)',\n",
    "    'CTIS-CLIIC',\n",
    "    'CHNG-CLI',\n",
    "    'CHNG-COVID',\n",
    "    'DV-CLI', \n",
    "    'Google-AA',\n",
    "    'Simple average',\n",
    "]\n",
    "\n",
    "def get_availability(all_err_df, full_index, sensor_list):\n",
    "    lag_sensor_availability = {}\n",
    "    available_index = full_index.copy()\n",
    "    for sensor in sensor_list:\n",
    "        tmp = all_err_df[all_err_df.sensor.eq(sensor)]\n",
    "        tmp = tmp.set_index(['geo', 'as_of'])\n",
    "        available_index = available_index.intersection(tmp.index)\n",
    "        \n",
    "    return available_index\n",
    "\n",
    "def get_availability_by_lag(lag, all_err_df, full_index, sensor_list, verbose=True):\n",
    "    lag_sensor_availability = {}\n",
    "    available_index = full_index.copy()\n",
    "    for sensor in sensor_list:\n",
    "        tmp = all_err_df[all_err_df.sensor.eq(sensor) & all_err_df.lag.eq(lag)]\n",
    "        tmp = tmp.set_index(['geo', 'as_of'])\n",
    "        sensor_available_index = full_index.intersection(tmp.index)\n",
    "        available_index = available_index.intersection(tmp.index)\n",
    "        lag_sensor_availability[sensor] = len(sensor_available_index) / len(full_index)\n",
    "        if verbose:\n",
    "            print(lag,\n",
    "                f'{sensor:20s}{100*len(sensor_available_index)/len(full_index):3.3f}',\n",
    "                f'{100*len(available_index)/len(full_index):3.3f}')\n",
    "        \n",
    "    return available_index, lag_sensor_availability\n",
    "\n",
    "sensor_availability = {}\n",
    "total_availability = {}\n",
    "availability = {}\n",
    "total_availability_no_google_aa = {}\n",
    "availablity_no_google_aa = {}\n",
    "print(\"\\t\\t\\tSensor\\tTotal\")\n",
    "for lag in range(1, max_eval_lag + 1):\n",
    "    print(lag)\n",
    "    sensor_list = [s for s in plot_sensors if s in sensor_latency[lag]]\n",
    "    available_index, lag_sensor_availability = get_availability_by_lag(lag, all_err_df, full_index, sensor_list)\n",
    "    sensor_availability[lag] = lag_sensor_availability\n",
    "    total_availability[lag] = len(available_index) / len(full_index)\n",
    "    availability[lag] = available_index\n",
    "    print('--- no google aa ---')\n",
    "    sensor_list = [s for s in sensor_list if s != 'Google-AA']\n",
    "    available_index, lag_sensor_availability = get_availability_by_lag(lag, all_err_df, full_index, sensor_list)\n",
    "    total_availability_no_google_aa[lag] = len(available_index) / len(full_index)\n",
    "    availablity_no_google_aa[lag] = available_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc205e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame.from_dict(sensor_availability)\n",
    "tmp = pd.concat([\n",
    "    tmp.reindex(plot_sensors),\n",
    "    pd.DataFrame({\n",
    "        'lag': total_availability.keys(), \n",
    "         'Intersection': total_availability.values()}).set_index('lag').T,\n",
    "      pd.DataFrame({\n",
    "        'lag': total_availability_no_google_aa.keys(), \n",
    "         'Intersection without\\nGoogle-AA': total_availability_no_google_aa.values()}).set_index('lag').T,\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.heatmap(tmp, annot=True, cmap=\"BuPu\", linewidths=.25, vmin=0,\n",
    "            cbar_kws={'label': 'Proportion', 'shrink': 0.8})\n",
    "plt.xlabel('Days back from nowcast time')\n",
    "plt.title('Sensor availability during estimation period\\n')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/availability.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3e15d",
   "metadata": {},
   "source": [
    "## MAE line plot and rank plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b878856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_legend_map = {\n",
    "    'Simple average (+claims)': 'Simple average',\n",
    "    'Simple average (+claims) (-google-aa)': 'Simple average',\n",
    "    'Simple average (-google-aa)': 'Simple average',\n",
    "    'Simple regression (+claims)': 'Simple regression',\n",
    "    'Ridge (+claims)': 'Ridge',\n",
    "    'Lasso (+claims)': 'Lasso',\n",
    "    'KF-SF (+claims)': 'KF-SF',\n",
    "}\n",
    "strip_claims = lambda s: s.replace(' (+claims)', '')\n",
    "strip_google_aa = lambda s: s.replace(' (-google-aa)', '')\n",
    "\n",
    "def plot(err_df, full_index, sensor_list, line_lags, rank_lags, out_name):\n",
    "    available_index = get_availability(err_df, full_index, sensor_list)\n",
    "    tmp = err_df[err_df.lag.isin(line_lags) & err_df.sensor.isin(sensor_list)].set_index(['geo', 'as_of'])\n",
    "    plot_df = tmp.loc[available_index].reset_index()\n",
    "    plot_df.replace(label_legend_map, inplace=True)\n",
    "    stripped_hue_order = [strip_google_aa(strip_claims(s)) for s in version['sensor_list']]\n",
    "    \n",
    "    # create lineplot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.lineplot(data=plot_df,\n",
    "        x='lag',\n",
    "        y='abs_err',\n",
    "        hue='sensor',\n",
    "        hue_order=stripped_hue_order,\n",
    "        marker='o',\n",
    "        markers=marker_map,\n",
    "        dashes=False, \n",
    "        palette=color_map,\n",
    "        n_boot=500,\n",
    "        err_kws={'alpha':0.1}\n",
    "    )\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.xlabel('Days back from nowcast time')\n",
    "    plt.ylabel('Mean absolute error')\n",
    "    plt.xticks(line_lags[::2])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./figures/lineplot_{out_name}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    # create rank plot\n",
    "    plot_df = []\n",
    "    for lag in rank_lags:\n",
    "        available_index, _ = get_availability_by_lag(lag, err_df, full_index, sensor_list, verbose=False)\n",
    "        tmp = err_df[err_df.lag.eq(lag) & err_df.sensor.isin(sensor_list)].set_index(['geo', 'as_of'])\n",
    "        plot_df.append(tmp.loc[available_index].reset_index())\n",
    "    plot_df = pd.concat(plot_df, ignore_index=True)\n",
    "    plot_df.replace(label_legend_map, inplace=True)\n",
    "    \n",
    "    sensor_rank_df = plot_df.groupby(['dates', 'geo', 'sensor', 'lag']).abs_err.mean().reset_index()\n",
    "    sensor_rank_df['rank'] = sensor_rank_df.groupby(['dates', 'geo', 'lag']).abs_err.rank('dense', ascending=True)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    g = sns.histplot(\n",
    "        data=sensor_rank_df,\n",
    "        x='rank',\n",
    "        hue='sensor',\n",
    "        hue_order=stripped_hue_order,\n",
    "        element='bars',\n",
    "        discrete=True,\n",
    "        multiple='fill',\n",
    "        palette=color_map,\n",
    "        legend=True)\n",
    "\n",
    "    g.legend(handles=g.legend_.legendHandles, labels=[t.get_text() for t in g.legend_.texts],\n",
    "              title=None,\n",
    "              bbox_to_anchor=(1, 1), \n",
    "             loc='upper left', fontsize=10)\n",
    "    g.set_xticks(np.arange(1, len(sensor_list)+1))\n",
    "    g.set_xticklabels(np.arange(1, len(sensor_list)+1))\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.savefig(f'./figures/rankplot_{out_name}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "versions = {\n",
    "    'claims_no_google_aa': {\n",
    "        'sensor_list': ['NTF (tapered)', 'AR(3)', 'CTIS-CLIIC',\n",
    "                       'CHNG-CLI','CHNG-COVID','DV-CLI', 'Simple average (+claims) (-google-aa)'],\n",
    "        'line_lags': np.arange(1, max_eval_lag+1),\n",
    "        'rank_lags': [4, 5, 6, 7, 8],\n",
    "    },\n",
    "    'claims': {\n",
    "        'sensor_list': ['NTF (tapered)', 'AR(3)', 'CTIS-CLIIC', 'CHNG-CLI',\n",
    "               'CHNG-COVID', 'DV-CLI','Google-AA', 'Simple average (+claims)'],\n",
    "        'line_lags': np.arange(1, max_eval_lag+1),\n",
    "        'rank_lags': [4, 5, 6, 7, 8],\n",
    "    },\n",
    "    'no_claims_no_google_aa': {\n",
    "        'sensor_list': ['NTF (tapered)', 'AR(3)', 'CTIS-CLIIC', \n",
    "                               'Simple average (-google-aa)'],\n",
    "        'line_lags': np.arange(1, max_eval_lag+1),\n",
    "        'rank_lags': [2, 3, 4, 5, 6],\n",
    "    },\n",
    "    'no_claims': {\n",
    "        'sensor_list': ['NTF (tapered)', 'AR(3)','CTIS-CLIIC', \n",
    "                            'Google-AA', 'Simple average'],\n",
    "        'line_lags': np.arange(1, max_eval_lag+1),\n",
    "        'rank_lags': [2, 3, 4, 5, 6],\n",
    "    },\n",
    "}\n",
    "    \n",
    "full_index = pd.MultiIndex.from_product([evaluation_geos, evaluation_as_of_range], names=['geo', 'as_of'])\n",
    "for version_key, version in versions.items():\n",
    "    print(version_key)\n",
    "    err_df = all_err_df[all_err_df.sensor.isin(version['sensor_list'])]\n",
    "    plot(err_df, full_index, version['sensor_list'], version['line_lags'], version['rank_lags'], version_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024525b",
   "metadata": {},
   "source": [
    "## Fusion box plot and rank plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e871725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_state_type(x):\n",
    "    if x < 5:\n",
    "        return 'Small'\n",
    "    if x < 15:\n",
    "        return 'Medium'\n",
    "    return 'Large'\n",
    "\n",
    "map_fips_to_state = dict((v,k) for k,v in Config.state_fips.items())\n",
    "\n",
    "def plot_fusion(err_df, full_index, sensor_list, boxen_lags, rank_lags, out_name):\n",
    "    available_index = get_availability(err_df, full_index, sensor_list)\n",
    "    tmp = err_df[err_df.lag.isin(boxen_lags) & err_df.sensor.isin(sensor_list)].set_index(['geo', 'as_of'])\n",
    "    plot_df = tmp.loc[available_index].reset_index()\n",
    "    plot_df.replace(label_legend_map, inplace=True)\n",
    "    \n",
    "    # boxen plot\n",
    "    plot_df['state'] = plot_df['geo'].apply(lambda x: map_fips_to_state[x[:2]] if get_geo_type(x) == 'county' else x)\n",
    "    plot_df['n_geos_in_state'] = plot_df.state.apply(lambda x: len(state_map[x]))\n",
    "    plot_df_states = plot_df.groupby(['lag', 'sensor', 'state', 'n_geos_in_state']).abs_err.mean().reset_index()\n",
    "    plot_df_states['state_size'] = plot_df_states.n_geos_in_state.apply(map_state_type)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.set_palette(\"colorblind\")\n",
    "    g = sns.catplot(\n",
    "        data=plot_df_states,\n",
    "        x='lag',\n",
    "        y='abs_err',\n",
    "        hue='sensor',\n",
    "        col='state_size', \n",
    "        kind='boxen',\n",
    "        hue_order=[\n",
    "            'Simple average', \n",
    "            'Simple regression',\n",
    "            'Lasso', \n",
    "            'Ridge',\n",
    "            'KF-SF'],\n",
    "        col_order=['Small', 'Medium', 'Large'],\n",
    "        palette=color_map,\n",
    "        showfliers=False,\n",
    "        legend=False,\n",
    "        saturation=1,\n",
    "    )\n",
    "    g.set_titles(\"{col_name} states\")\n",
    "    plt.legend(bbox_to_anchor=(.58, .975), loc='upper left', fontsize=10)\n",
    "    g.set_xlabels('Days back from nowcast time')\n",
    "    g.set_ylabels('Mean absolute error')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./figures/boxenplot_{out_name}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # rank plot\n",
    "    # for each lag, figure out the intersection of dates\n",
    "    plot_df = []\n",
    "    for lag in rank_lags:\n",
    "        available_index, _ = get_availability_by_lag(lag, err_df, full_index, sensor_list, verbose=False)\n",
    "        tmp = err_df[err_df.lag.eq(lag) & err_df.sensor.isin(sensor_list)].set_index(['geo', 'as_of'])\n",
    "        plot_df.append(tmp.loc[available_index].reset_index())\n",
    "    plot_df = pd.concat(plot_df, ignore_index=True)\n",
    "    plot_df.replace(label_legend_map, inplace=True)\n",
    "    ensemble_rank_df = plot_df.groupby(['dates', 'geo', 'sensor', 'lag']).abs_err.mean().reset_index()\n",
    "    ensemble_rank_df['rank'] = ensemble_rank_df.groupby(['dates', 'geo', 'lag']).abs_err.rank('dense', ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    g = sns.histplot(\n",
    "        data=ensemble_rank_df,\n",
    "        x='rank',\n",
    "        hue='sensor',\n",
    "        hue_order=[strip_claims(s) for s in version['sensor_list']],\n",
    "        element='bars',\n",
    "        discrete=True,\n",
    "        multiple='fill',\n",
    "        palette=color_map,\n",
    "        legend=True)\n",
    "\n",
    "    g.legend(handles=g.legend_.legendHandles, labels=[t.get_text() for t in g.legend_.texts],\n",
    "              title=None,\n",
    "              bbox_to_anchor=(1, 1), \n",
    "             loc='upper left', fontsize=10)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.savefig(f'./figures/rankplot_fusion_{out_name}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "versions = {\n",
    "    'claims': {\n",
    "        'sensor_list': ['Simple average (+claims)', 'Simple regression (+claims)', \n",
    "                        'Ridge (+claims)', 'Lasso (+claims)', 'KF-SF (+claims)'],\n",
    "        'boxen_lags': np.arange(1, max_eval_lag+1),\n",
    "        'rank_lags': [4, 5, 6, 7, 8],\n",
    "    },\n",
    "    'no_claims': {\n",
    "        'sensor_list': ['Simple average', 'Simple regression', 'Ridge', 'Lasso', 'KF-SF'],\n",
    "        'boxen_lags': np.arange(1, max_eval_lag+1),\n",
    "        'rank_lags': [1, 2, 3, 4, 5],\n",
    "    },  \n",
    "}\n",
    "\n",
    "full_index = pd.MultiIndex.from_product([evaluation_geos, evaluation_as_of_range], names=['geo', 'as_of'])\n",
    "for version_key, version in versions.items():\n",
    "    print(version_key)\n",
    "    err_df = all_err_df[all_err_df.sensor.isin(version['sensor_list'])]\n",
    "    plot_fusion(err_df, full_index, version['sensor_list'],\n",
    "                version['boxen_lags'], version['rank_lags'], version_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
