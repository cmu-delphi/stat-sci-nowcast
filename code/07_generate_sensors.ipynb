{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5685945a",
   "metadata": {},
   "source": [
    "# Generate sensors from indicator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f268555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# first party\n",
    "from config import Config\n",
    "from data_containers import LocationSeries, SensorConfig\n",
    "import sensorization.regression as reg\n",
    "import sensorization.ar as ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Directory:\n",
    "    ROOT = '../data/'\n",
    "    \n",
    "    def __init__(self, gt_indicator = Config.ground_truth_indicator):\n",
    "        self.gt = gt_indicator\n",
    "        self.infections_root_dir = './results/ntf_tapered/'\n",
    "        self.indicator_root_dir = os.path.join(Directory.ROOT, 'indicators')\n",
    "        self.sensor_root_dir = os.path.join(Directory.ROOT, 'sensors')\n",
    "        self.jhu_path = os.path.join(\n",
    "            Directory.ROOT, f'jhu-csse_confirmed_incidence_prop/{self.gt.source}_{self.gt.signal}')\n",
    "       \n",
    "    def deconv_gt_file(self, as_of):\n",
    "        return os.path.join(self.infections_root_dir, f'as_of_{as_of}.p')\n",
    "    \n",
    "    def indicator_file(self, indicator, as_of):\n",
    "        return os.path.join(\n",
    "            self.indicator_root_dir,\n",
    "            f'{indicator.source}-{indicator.signal}_{as_of}.p')\n",
    "    \n",
    "    def sensor_file(self, config, as_of):\n",
    "        return os.path.join(\n",
    "            self.sensor_root_dir,\n",
    "            f'{config.source}_{config.signal}_{as_of}.p')\n",
    "    \n",
    "    def maybe_load_file(self, file_name, verbose=False):\n",
    "        if not os.path.isfile(file_name):\n",
    "            if verbose:\n",
    "                print(file_name, 'does not exist')\n",
    "            return False\n",
    "        \n",
    "        return pickle.load(open(file_name, 'rb'))\n",
    "    \n",
    "    def maybe_write_file(self, data, file_name, overwrite=False, verbose=False):\n",
    "        if os.path.isfile(file_name) and not overwrite:\n",
    "            if verbose:\n",
    "                print(file_name, 'exists')\n",
    "            return False\n",
    "        \n",
    "        dir_name = os.path.dirname(file_name)\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)   \n",
    "        \n",
    "        pickle.dump(data, open(file_name, 'wb'))\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def exists(file_name, overwrite=False):\n",
    "        if os.path.isfile(file_name) and not overwrite:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def conform(location_series):\n",
    "    if location_series is None:\n",
    "        return None\n",
    "    \n",
    "    if location_series.data is None or np.isnan(location_series.values).all():\n",
    "        return None\n",
    "    \n",
    "    if isinstance(location_series.dates[0], datetime):\n",
    "        location_series.data = dict(zip([d.date() for d in location_series.dates],\n",
    "                                        location_series.values))\n",
    "    return location_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22936aff",
   "metadata": {},
   "source": [
    "### Generate regression sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_dist_dir = \"../data/km_delay_distributions/\"\n",
    "as_of_range = Config.as_of_range\n",
    "infections_config = SensorConfig(\n",
    "    'jhu-csse', 'confirmed_incidence_prop','deconv_infections', 2)\n",
    "indicators = [Config.fb_cliic, Config.dv_cli, Config.google_aa, Config.chng_cli, Config.chng_covid]\n",
    "directory = Directory(infections_config)\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a604878",
   "metadata": {},
   "outputs": [],
   "source": [
    "for as_of in tqdm(as_of_range):\n",
    "    delay_dist = Config.get_delay_distribution(\n",
    "        as_of, storage_dir=delay_dist_dir)[as_of]\n",
    "    infections_file = directory.deconv_gt_file(as_of)\n",
    "    infections_data = directory.maybe_load_file(infections_file)\n",
    "    last_infections_date = as_of - timedelta(directory.gt.lag)\n",
    "    assert infections_data is not None\n",
    "    \n",
    "    for indicator in indicators:\n",
    "        indicator_file = directory.indicator_file(indicator, as_of)\n",
    "        indicator_data = directory.maybe_load_file(indicator_file)\n",
    "        output_file = directory.sensor_file(indicator, as_of)\n",
    "        last_indicator_date = as_of - timedelta(indicator.lag)\n",
    "        last_date = min(last_infections_date, last_indicator_date)\n",
    "        \n",
    "        if directory.exists(output_file, overwrite):\n",
    "            print(output_file, 'exists')\n",
    "            continue\n",
    "            \n",
    "        if not indicator_data:\n",
    "            print(as_of, indicator.source, 'not available')\n",
    "            continue\n",
    "            \n",
    "        output = {}\n",
    "        available_at_lowest_lag = True\n",
    "        for loc, series in indicator_data.items():\n",
    "            covariates = conform(series)\n",
    "            response = conform(infections_data[series.geo_value])\n",
    "            \n",
    "            # Check if indicator was available at its lowest latency\n",
    "            if covariates.dates[-1] != last_indicator_date:\n",
    "                print(as_of, indicator.source, f'not available at latency {indicator.lag}')\n",
    "                available_at_lowest_lag = False\n",
    "                break\n",
    "                \n",
    "            # Check if response was available at its lowest latency\n",
    "            if response.dates[-1] != last_infections_date:\n",
    "                print(as_of, \"infections\", f'not available at latency {directory.gt.lag}')\n",
    "                available_at_lowest_lag = False\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                output[loc] = reg.compute_regression_sensor(last_date, series, response, delay_dist)\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                if str(e) != \"Singular matrix\":\n",
    "                    raise\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if available_at_lowest_lag:\n",
    "            directory.maybe_write_file(output, output_file, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3da16a",
   "metadata": {},
   "source": [
    "### Generate autoregressive sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = SensorConfig('ar3', 'ntf_tapered_infections', 'ar3', lag=1)\n",
    "overwrite = True\n",
    "\n",
    "for as_of in tqdm(as_of_range):\n",
    "    delay_dist = Config.get_delay_distribution(\n",
    "        as_of, storage_dir=delay_dist_dir)[as_of]\n",
    "    infections_file = directory.deconv_gt_file(as_of)\n",
    "    infections_data = directory.maybe_load_file(infections_file)\n",
    "    last_infections_date = as_of - timedelta(directory.gt.lag)\n",
    "    assert infections_data is not None\n",
    "    \n",
    "    output_file = directory.sensor_file(indicator, as_of)\n",
    "    last_date = as_of - timedelta(indicator.lag)\n",
    "\n",
    "    if directory.exists(output_file, overwrite):\n",
    "        print(output_file, 'exists')\n",
    "        continue\n",
    "\n",
    "    output = {}\n",
    "    available_at_lowest_lag = True \n",
    "    for loc, series in infections_data.items():\n",
    "        # Check if indicator was available at lowest latency\n",
    "        if series.dates[-1] != last_infections_date:\n",
    "            print(as_of, f'infections not available at latency {directory.gt.lag}')\n",
    "            available_at_lowest_lag = False\n",
    "            break\n",
    "\n",
    "        response = conform(infections_data[series.geo_value])\n",
    "        est = ar.compute_ar_sensor(\n",
    "            last_date, response, response, delay_dist,\n",
    "            [1, 2, 3], 1)\n",
    "        \n",
    "        # Fill in first 3 days which are missing with the AR model\n",
    "        # using the mean\n",
    "        extra_dates = [d.date() for d in date_range(\n",
    "            series.dates[0], est.dates[0] - timedelta(1))]\n",
    "        extra_vals = np.full((len(extra_dates),), np.mean(est.values))\n",
    "        output[loc] = LocationSeries(\n",
    "            est.geo_value, est.geo_type, dict(zip(\n",
    "                np.r_[extra_dates, est.dates], np.r_[extra_vals, est.values]))\n",
    "        )\n",
    "\n",
    "    if available_at_lowest_lag:\n",
    "        directory.maybe_write_file(output, output_file, overwrite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}